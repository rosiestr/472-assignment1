{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[] 3.1 Use gensim.downloader.load to load the word2vec-google-news-300 pretrained embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "word2vec_googlenews = gensim.downloader.load('word2vec-google-news-300')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3.2 Use the tokenizer from nltk to extract words from the Reddit posts. Display the number of tokens in the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2642128\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gzip\n",
    "import nltk\n",
    "\n",
    "# jsonfiledirectory = \"/Users/rosiers/Documents/GitHub/472-assignment1/goemotions.json.gz\"\n",
    "jsonfiledirectory = \"C:\\\\Users\\\\Krish\\\\.vscode\\\\472-assignment1\\\\goemotions.json.gz\"\n",
    "\n",
    "with gzip.open(jsonfiledirectory, \"r\") as f:\n",
    "    data = json.loads(f.read().decode(\"utf-8\"))\n",
    "strings_token = []\n",
    "for item in data:\n",
    "    strings_token.append(nltk.word_tokenize(item[0]))\n",
    "count = 0\n",
    "for str in strings_token:\n",
    "    count = count + len(str)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3.3 Compute the embedding of a Reddit post as the average of the embeddings of its words. If a word has no embedding in Word2Vec, skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0625732421875, 0.0309539794921875, 0.0525146484375, 0.18604736328125, -0.09674072265625, 0.0177734375, 0.0715301513671875, -0.0430419921875, -0.009185791015625, -0.009529876708984374, -0.121923828125, -0.18212890625, -0.0642822265625, 0.03070068359375, -0.1669189453125, 0.1212158203125, 0.067041015625, 0.095947265625, 0.0786376953125, -0.1344970703125, -0.0189697265625, 0.01287841796875, 0.184210205078125, 0.0110565185546875, 0.02649974822998047, 0.051744842529296876, -0.115362548828125, 0.043670654296875, 0.01415557861328125, -0.053167724609375, -0.068359375, 0.14326171875, -0.038232421875, -0.06484375, -0.10544891357421875, 0.04044189453125, 0.087939453125, 0.051953125, 0.000640869140625, 0.11961212158203124, 0.04735107421875, -0.04951171875, 0.259423828125, -0.0633392333984375, -0.01748046875, -0.023974609375, 0.02947998046875, -0.10185546875, 0.0018310546875, -0.01885986328125, -0.09895172119140624, 0.0999755859375, -0.00535888671875, 0.06209716796875, 0.0124420166015625, -0.00230712890625, -0.03419036865234375, -0.04813232421875, -0.0088623046875, -0.013018798828125, 0.01180419921875, 0.030804443359375, -0.099658203125, -0.1099853515625, 0.025469970703125, -0.10306396484375, -0.12239990234375, 0.098779296875, -0.1070556640625, 0.00083770751953125, 0.16103515625, 0.1147857666015625, 0.045098876953125, -0.02919921875, -0.2867919921875, -0.140869140625, 0.08260650634765625, 0.107275390625, 0.048114013671875, 0.12018585205078125, -0.072882080078125, -0.017352294921875, 0.02330322265625, 0.009228515625, -0.075921630859375, -0.0625244140625, 0.016351318359375, 0.22568359375, -0.00138092041015625, 0.010997962951660157, 0.0052947998046875, 0.18134765625, -0.0942413330078125, -0.111279296875, -0.02017822265625, -0.05692138671875, 0.1388214111328125, 0.0057861328125, 0.010333251953125, 0.043994140625, -0.128759765625, -0.050413894653320315, -0.014532470703125, 0.052214860916137695, -0.144012451171875, -0.08460845947265624, -0.1317626953125, -0.00274658203125, 0.028350830078125, -0.0848602294921875, -0.135498046875, -0.135711669921875, -0.07398681640625, 0.04893798828125, 0.07822265625, -0.024769973754882813, 0.042498779296875, -0.09033203125, 0.0416259765625, 0.0197265625, -0.1191802978515625, -0.0377777099609375, -0.01749763488769531, 0.1109130859375, -0.0281982421875, -0.06864395141601562, -0.151763916015625, -0.0123046875, 0.0315673828125, -0.0196044921875, -0.14036102294921876, -0.116436767578125, -0.058203125, 0.01986083984375, 0.04188232421875, -0.18193359375, -0.0950927734375, 0.031597900390625, 0.0433837890625, 0.10572052001953125, 0.09912109375, -0.1114501953125, 2.44140625e-05, -0.05406951904296875, 0.09319610595703125, -0.015087890625, -0.0016204833984375, -0.168414306640625, -0.00079345703125, -0.0535003662109375, 0.12933349609375, 0.05709228515625, -0.09605712890625, -0.0371337890625, -0.00335693359375, -0.012408447265625, -0.07098388671875, -0.022168064117431642, -0.0912353515625, 0.02540283203125, 0.01253509521484375, 0.1392333984375, -0.052386474609375, 0.13531036376953126, 0.030023193359375, -0.19501953125, 0.013485336303710937, -0.0671630859375, -0.0607421875, -0.0278564453125, -0.1904296875, 0.005731201171875, 0.008831787109375, -0.0300048828125, -0.05377960205078125, 0.03004150390625, 0.18291015625, -0.10030517578125, -0.038525390625, 0.014902114868164062, -0.10904541015625, -0.0359619140625, 0.03994140625, -0.034356689453125, -0.018743896484375, 0.034906005859375, -0.060107421875, -0.04114990234375, 0.06004638671875, 0.033355712890625, 0.085809326171875, 0.059228515625, 0.005615234375, 0.0198638916015625, 0.06031494140625, 0.021099853515625, -0.06463623046875, -0.0318115234375, -0.020721435546875, -0.075732421875, -0.027880859375, 0.08692626953125, -0.04013824462890625, -0.02333984375, -0.020684814453125, 0.0021728515625, -0.12325439453125, -0.122637939453125, 0.0019775390625, -0.03330078125, -0.0225341796875, 0.08830299377441406, -0.141845703125, 0.05230712890625, -0.18216552734375, -0.0759033203125, 0.164990234375, 0.0138275146484375, -0.11171875, -0.05511474609375, -0.10725936889648438, -0.0187042236328125, -0.0390380859375, -0.054547119140625, 0.12385711669921876, -0.07474365234375, 0.1472900390625, 0.0400146484375, -0.08165283203125, -0.016204833984375, -0.00128173828125, -0.1072021484375, -0.044879150390625, -0.01455078125, 0.08670654296875, 0.028955078125, -0.034765625, 0.045947265625, 0.1225860595703125, 0.00137939453125, -0.0128173828125, 0.00806884765625, 0.05528717041015625, -0.11429443359375, -0.08203125, -0.0048828125, -0.01571044921875, 0.1451202392578125, 0.00057373046875, -0.073876953125, 0.0723388671875, -0.0331298828125, 0.09595947265625, 0.09939756393432617, 0.082196044921875, -0.12406005859375, -0.038983154296875, 0.015087890625, 0.007763671875, -0.071612548828125, -0.0805908203125, -0.016604232788085937, -0.140087890625, 0.0218994140625, 0.044525146484375, 0.08011245727539062, -0.0426971435546875, 0.0084991455078125, -0.0876190185546875, 0.016998291015625, 0.033294677734375, 0.1675048828125, 0.221673583984375, 0.16858062744140626, -0.0201171875, -0.06920166015625, -0.0619720458984375, -0.13974609375, -0.05234375, 0.03576812744140625, 0.039697265625, -0.0860595703125, 0.088262939453125, 0.115185546875, -0.00801544189453125, 0.0279754638671875, -0.0004669189453125, -0.1109375, 0.02270050048828125, 0.0727294921875, -0.01107177734375, 0.15234375, -0.112164306640625, 0.05659828186035156, -0.05213623046875, 0.00498046875, 0.01402587890625, -0.098388671875, -0.0352783203125, -0.00509033203125]\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to add each average embedding to\n",
    "embeddings = []\n",
    "#strings_token is the tokenized sentences\n",
    "for s in strings_token:\n",
    "    #for each sentence create a vector to hold the embeddings for each token in the string\n",
    "    # it will be wiped each time\n",
    "    strings_embedding = []\n",
    "\n",
    "    #for each token in the sentence check if it has embedding and add it to the list or skip\n",
    "    for tkn in s:\n",
    "        if tkn in word2vec_googlenews:\n",
    "            strings_embedding.append(word2vec_googlenews[tkn])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    #use zip to put all elements from each embedding into list of the same index\n",
    "    embd = zip(*strings_embedding)\n",
    "    #calculate the average by finding the sum of the elements at each index, and dividing it by the number of elements\n",
    "    average_embedding = []\n",
    "    for e in embd:\n",
    "        avg = sum(e)/len(e)\n",
    "        average_embedding.append(avg)\n",
    "    #once all the averages are computed, append the average embedding as an element\n",
    "    embeddings.append(average_embedding)\n",
    "print(embeddings[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3.4 Compute and display the overall hit rates of the training and test sets (i.e. the % of words in the Reddit posts for which an embedding is found in Word2Vec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall hitrates:\n",
      "0.7745063827339175\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for i in strings_token: \n",
    "    for tkn in i:\n",
    "        if tkn in word2vec_googlenews:\n",
    "            counter= counter+1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "print(\"Overall hitrates:\")\n",
    "hitrate= counter/count\n",
    "print(hitrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3.5 Train a Base-MLP: a Multi-Layered Perceptron (neural network.MLPClassifier) with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.028157552083333332, 0.19417317708333334, -0.033040364583333336, 0.13557942708333334, -0.06819661458333333, 0.09309895833333333, 0.04833984375, 0.010498046875, 0.053466796875, 0.10432942708333333, -0.010904947916666666, -0.171875, -0.10477701822916667, -0.0126953125, -0.16227213541666666, 0.055501302083333336, 0.07666015625, 0.1513671875, -0.16288248697916666, -0.25439453125, -0.19590250651041666, 0.07405598958333333, 0.19184048970540366, -0.01556396484375, 0.072021484375, 0.21044921875, -0.15681966145833334, 0.046915690104166664, 0.11165364583333333, -0.03656005859375, -0.021158854166666668, 0.0087890625, 0.0947265625, -0.17431640625, -0.11397298177083333, 0.10872395833333333, -0.1049041748046875, 0.1746826171875, -0.04638671875, 0.14206949869791666, 0.17154947916666666, -0.03759765625, 0.16300455729166666, -0.09090169270833333, 0.05224609375, -0.06368001302083333, -0.041097005208333336, -0.018239339192708332, -0.0052490234375, 0.0535888671875, -0.2333984375, 0.13704427083333334, 0.07747395833333333, -0.013264973958333334, 0.09138997395833333, 0.024983723958333332, -0.1787109375, -0.014383951822916666, -0.010416666666666666, -0.08186848958333333, 0.01953125, 0.18229166666666666, -0.2392578125, -0.11222330729166667, -0.06343587239583333, -0.13899739583333334, 0.016194661458333332, 0.1431884765625, -0.17805989583333334, -0.07967122395833333, 0.169921875, 0.025065104166666668, -0.10782877604166667, 0.11539713541666667, -0.19466145833333334, 0.0008138020833333334, 0.008626302083333334, 0.17354329427083334, -0.09588623046875, 0.14111328125, -0.101318359375, 0.039296468098958336, -0.13126627604166666, 0.0576171875, -0.1572265625, -0.23046875, -0.15185546875, 0.15134684244791666, 0.1416015625, -0.06510416666666667, 0.0791015625, 0.06734212239583333, 0.10005696614583333, -0.17936197916666666, 0.0098876953125, -0.039510091145833336, 0.1875, 0.13199869791666666, 0.07747395833333333, 0.037760416666666664, 0.2158203125, -0.0021158854166666665, -0.0582275390625, -0.08384195963541667, 0.008870442708333334, 0.2566426595052083, -0.11002604166666667, -0.1611328125, 0.07584635416666667, -0.024251302083333332, 0.0021158854166666665, 0.15083821614583334, 0.096923828125, -0.21240234375, 0.3821614583333333, -0.0751953125, 0.044270833333333336, 0.014811197916666666, -0.059407552083333336, 0.05908203125, -0.18782552083333334, 0.06614176432291667, -0.1512451171875, 0.06575520833333333, 0.056640625, -0.06502278645833333, -0.010416666666666666, 0.0732421875, 0.021321614583333332, -0.06917317708333333, -0.09769694010416667, -0.14595540364583334, 0.044423421223958336, -0.02197265625, -0.07108561197916667, -0.067626953125, -0.06527964274088542, -0.013020833333333334, 0.053751627604166664, -0.0023600260416666665, 0.17854817708333334, -0.12947591145833334, 0.08642578125, -0.034779866536458336, -0.14518229166666666, -0.2962239583333333, -0.07763671875, -0.06339518229166667, 0.06803385416666667, -0.08984375, 0.15608723958333334, -0.21822102864583334, -0.020467122395833332, 0.020345052083333332, -0.11360677083333333, 0.02215576171875, -0.017110188802083332, 0.005045572916666667, -0.08834330240885417, -0.1015625, -0.017822265625, 0.089752197265625, 0.06146240234375, 0.0892333984375, 0.14052836100260416, -0.06920353571573894, 0.036936442057291664, -0.07157389322916667, 0.01611328125, -0.03662109375, -0.22965494791666666, -0.045166015625, -0.05206298828125, -0.09781901041666667, -0.06453450520833333, 0.11800130208333333, 0.021158854166666668, -0.22395833333333334, 0.08585611979166667, -0.1260986328125, 0.027669270833333332, -0.08561197916666667, 0.054229736328125, 0.10188802083333333, -0.1103515625, 0.09134928385416667, -0.19368489583333334, -0.035319010416666664, -0.004384358723958333, 0.15185546875, 0.11873372395833333, -0.12744140625, -0.061665852864583336, -0.01361083984375, -0.035725911458333336, 0.042805989583333336, 0.004638671875, -0.15950520833333334, 0.201080322265625, -0.1710205078125, 0.010904947916666666, 0.07942708333333333, -0.09307861328125, -0.10367838541666667, 0.040283203125, -0.09358723958333333, -0.2021484375, 0.09635416666666667, -0.146484375, -0.10595703125, -0.0439453125, -0.039581298828125, 0.039591471354166664, 0.15999348958333334, -0.22477213541666666, 0.0003255208333333333, 0.11735026041666667, -0.06331380208333333, 0.0019124348958333333, 0.028076171875, -0.14013671875, 0.022501627604166668, 0.00439453125, -0.10091145833333333, 0.07047526041666667, 0.07763671875, 0.06412760416666667, -0.0006993611653645834, -0.054606119791666664, 0.052154541015625, -0.009220123291015625, -0.012906392415364584, 0.006506601969401042, 0.06608072916666667, 0.10701497395833333, -0.052490234375, -0.00016276041666666666, -0.06282552083333333, 0.1068115234375, 0.1229248046875, 0.23979822794596353, 0.14794921875, 0.11271158854166667, -0.21305338541666666, 0.03814697265625, 0.08984375, -0.035970052083333336, 0.3141276041666667, -0.041514078776041664, -0.06632486979166667, 0.11393229166666667, 0.049634297688802086, 0.18896484375, 0.15478515625, -0.19669596354166666, -0.17903645833333334, -0.01318359375, 0.07525634765625, 0.08349609375, -0.07845052083333333, -0.08528645833333333, 0.1962890625, -0.025777180989583332, -0.0782470703125, -0.037027994791666664, -0.021199544270833332, -0.032063802083333336, 0.01513671875, 0.035481770833333336, -0.0380859375, -0.08284505208333333, 0.24983723958333334, 0.03125, -0.14017740885416666, -0.12748209635416666, -0.0026652018229166665, -0.09928385416666667, -0.090087890625, 0.00244140625, 0.13850911458333334, -0.0078125, -0.010416666666666666, 0.024739583333333332, -0.050455729166666664, -0.0640869140625, -0.06429036458333333, -0.09989420572916667, 0.033040364583333336, -0.14762369791666666, -0.034830729166666664, 0.0005289713541666666, 0.2734375, -0.037923177083333336, 0.15657552083333334, -0.06380208333333333, -0.1494140625, -0.09783935546875, -0.08707682291666667, -0.048095703125, 0.237548828125]\n",
      "negative\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3428879059480852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "\n",
    "posts = []\n",
    "sentiment = []\n",
    "emotions = []\n",
    "for item in data:\n",
    "    posts.append(item[0])\n",
    "    sentiment.append(item[2])\n",
    "    emotions.append(item[1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, sentiment, test_size=0.2)\n",
    "\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "#x_numpy = numpy.array(X_train).reshape(-1,1)\n",
    "#y_numpy = numpy.array(y_train).reshape(-1,1)\n",
    "basemlp = MLPClassifier(max_iter=4)\n",
    "basemlp.fit(X_train, y_train)\n",
    "print(basemlp.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3.6 Train a Top-MLP: a better performing Multi-Layered Perceptron found with whatever hyperparameters you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP-MLP: \n",
      "0.3428879059480852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "topmlp = MLPClassifier(max_iter=5)\n",
    "\n",
    "param_grid = {\n",
    "    'activation' : ['tanh', 'relu', 'identity'],\n",
    "    'hidden_layer_sizes': (20,),\n",
    "    'solver': ['sgd', 'adam']\n",
    "}\n",
    "mlp_grid = GridSearchCV(topmlp, param_grid)\n",
    "mlp_grid.fit(X_train, y_train)\n",
    "print(\"TOP-MLP: \")\n",
    "print(mlp_grid.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3.7  Display the performance of your classifiers using metrics.classification report and add these to your performance file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

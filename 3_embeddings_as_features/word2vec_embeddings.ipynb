{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[] 3.1 Use gensim.downloader.load to load the word2vec-google-news-300 pretrained embedding model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "word2vec_googlenews = gensim.downloader.load('word2vec-google-news-300')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.2 Use the tokenizer from nltk to extract words from the Reddit posts. Display the number of tokens in the training set.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2642128\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gzip\n",
    "import nltk\n",
    "\n",
    "jsonfiledirectory = \"/Users/rosiers/Documents/GitHub/472-assignment1/goemotions.json.gz\"\n",
    "\n",
    "with gzip.open(jsonfiledirectory, \"r\") as f:\n",
    "    data = json.loads(f.read().decode(\"utf-8\"))\n",
    "strings_token = []\n",
    "for item in data:\n",
    "    strings_token.append(nltk.word_tokenize(item[0]))\n",
    "count = 0\n",
    "for str in strings_token:\n",
    "    count = count + len(str)\n",
    "print(count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.3 Compute the embedding of a Reddit post as the average of the embeddings of its words. If a word has no embedding in Word2Vec, skip it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03008478338068182, 0.09322903373024681, 0.030028256503018467, 0.07418684525923296, -0.11172897165471857, -0.04322398792613636, 0.03311573375355114, -0.0864347978071733, 0.03924486853859641, 0.06014737215909091, -0.012917258522727272, -0.15264060280539773, 0.002850619229403409, 0.010581276633522728, -0.13426659323952414, 0.09747314453125, 0.04696932705965909, 0.14509721235795456, -0.020958640358664772, -0.10691972212357954, 0.009561018510298296, 0.07356678355823863, 0.13306149569424716, -0.02817327325994318, 0.10091330788352272, -0.05473605069247159, -0.048980712890625, 0.05866172096946023, 0.012480302290482954, -0.005160245028409091, -0.02615148370916193, 0.03894979303533381, -0.022986672141335228, -0.020204023881392044, 0.08096036044034091, -0.052642822265625, 0.008706526322798296, -0.0028459375554865055, 0.05139090798117898, 0.07250282981178978, 0.14099675958806818, -0.051161332563920456, 0.12253639914772728, -0.016482960094105114, -0.0491301796653054, -0.04001548073508523, -0.06283985484730113, -0.006010575727982955, 0.027651700106534092, 0.035019267689098015, 0.022304361516779118, 0.01167574795809659, -0.03792918812144886, -0.08046098188920454, 0.001190185546875, 0.02551824396306818, 0.013101057572798296, -0.06125710227272727, 0.053679032759232956, -0.06611563942649147, -0.07225322723388672, 0.09904584017666904, -0.10134332830255682, -0.10824376886541193, -0.04634371670809659, 0.014359907670454546, 0.014032537286931818, 0.06929987127130682, -0.042703801935369316, 0.04270518909801136, 0.0731201171875, 0.00018310546875, 0.05469582297585227, -0.009952891956676136, -0.1368408203125, -0.07500665838068182, 0.006342107599431818, 0.06371654163707387, 0.01566557450727983, 0.15640397505326706, 0.0016867897727272727, 0.005131808194247159, 0.019228805195201527, 0.03931912508877841, -0.11962335759943182, -0.08336292613636363, -0.06932137229225853, 0.16641443425958807, 0.036092584783380684, -0.004757967862215909, 0.07193756103515625, 0.030666004527698864, -0.05372203480113636, -0.07972023703835228, -0.015010486949573864, -0.07073419744318182, 0.047026200727982956, 0.037409002130681816, -0.05294192921031605, 0.019284335049715908, 0.00017478249289772728, -0.025355252352627842, 0.049333052201704544, 0.11363636363636363, 0.009538130326704546, -0.05434903231534091, -0.024662364612926136, -0.04205599698153409, 0.06489146839488637, -0.08537847345525568, -0.0093536376953125, -0.024187954989346592, -0.01639764959161932, 0.05160799893465909, 0.10670055042613637, -0.03909024325284091, 0.010999159379438921, 0.03200461647727273, 0.08821660822088068, 0.07369717684659091, -0.13490711558948865, 0.03165782581676136, -0.012141834605823864, 0.0827789306640625, -0.024878068403764206, -0.07743419300426137, -0.06294944069602272, -0.026304765181107956, 0.01211270419034091, -0.055150812322443184, -0.06829556551846591, -0.10083077170632103, -0.02327173406427557, -0.021279421719637783, -0.022189053622159092, -0.05259288441051136, 0.007457386363636364, -0.002347079190340909, -0.018267544833096592, -0.010123512961647728, 0.06872003728693182, -0.043298201127485794, -0.0006880326704545455, 0.010063864968039772, 0.016493797302246094, -0.002858248623934659, -0.013248790394176136, -0.06747159090909091, -0.04900290749289773, 0.040029352361505684, 0.05658652565696023, 0.040695017034357246, -0.08599786324934526, 0.04238475452769886, -0.013807816938920454, 0.007974451238458807, -0.06185635653409091, -0.06837047230113637, -0.07611222700639204, 0.014273903586647728, 0.03908100995150479, 0.05811968716708096, 0.03281749378551136, -0.014928644353693182, 0.02143651788884943, -0.07761452414772728, 0.03933438387784091, -0.07328657670454546, 0.03710174560546875, -0.06414517489346591, -0.12187125466086647, 0.045629327947443184, -0.017569802024147728, 0.0018310546875, -0.025608409534801136, -0.011278325861150568, 0.03700949928977273, -0.12109097567471591, -0.04097470370205966, -0.01563262939453125, -0.09259111231023615, -0.07395796342329546, 0.045587019486860794, 0.03329571810635654, 0.013782848011363636, -0.03789242831143466, -0.03448971835049716, -0.0008295232599431819, 0.04327115145596591, 0.033113653009588066, 0.01775568181818182, -0.00234222412109375, 0.018553300337357956, -0.028087269176136364, -0.07948719371448863, -0.014995228160511364, -0.030559193004261364, -0.06506625088778409, -0.03345558860085227, -0.10789004239169034, 0.0002940784801136364, -0.029558008367365055, -0.0008059414950284091, 0.0018213445490056818, 0.01319243691184304, -0.03985248912464489, -0.019428599964488636, -0.0028846047141335225, -0.0022735595703125, 0.010384299538352272, 0.012573588978160511, 0.054490522904829544, -0.026442787863991478, 0.06149222634055398, -0.09236699884588068, 0.032560868696732956, 0.09641057794744318, 0.036607222123579544, -0.06482211026278409, 0.018467296253551136, -0.03733132102272727, 0.03258999911221591, -0.05140269886363636, 0.005622170188210227, 0.11895751953125, -0.04700955477627841, 0.026444868607954544, 0.0005611072887073864, 0.08063853870738637, 0.050225691361860794, -0.030895579944957386, -0.001800537109375, 0.06081875887784091, 0.017417214133522728, 0.054719404740767044, -0.02825372869318182, -0.020673405040394176, -0.064422607421875, 0.05973122336647727, 0.005968960848721591, 0.008952400901100853, -0.032587224786931816, 0.05748748779296875, -0.12331043590198863, -0.007927114313299006, 0.034723455255681816, 0.007650808854536576, 0.06677350130948154, -0.022110592235218395, -0.017539284446022728, -0.034454345703125, 0.058091597123579544, 0.06421383944424716, 0.043183760209517044, 0.10434792258522728, -0.035231156782670456, 0.05000374533913352, 0.039968317205255684, -0.04268230091441761, -0.07714288884943182, -0.05766365744850852, 0.011829723011363636, -0.09678511186079546, 0.014565901322798296, 0.03133825822310014, 0.08293429287997159, -0.041487260298295456, -0.09430070356889204, -0.07825521989302202, -0.009614424272017046, 0.025360107421875, 0.14833762428977273, 0.14303484829989346, 0.02312677556818182, 0.0028242631392045455, -0.06425337357954546, -0.06514393199573863, -0.10504982688210228, -0.018536047501997513, -0.06214488636363636, 0.033986871892755684, -0.004766290838068182, 0.08314098011363637, 0.09604991566051137, 0.014776750044389204, -0.04011813077059659, -0.09477095170454546, -0.022696755149147728, 0.034169977361505684, 0.03632632168856534, -0.02404264970259233, 0.020923961292613636, -0.08191888982599432, 0.03771695223721591, -0.07708462801846591, -0.011363636363636364, 0.047090010209517044, 0.015104814009232954, 0.027604536576704544, -0.01632135564630682]\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to add each average embedding to\n",
    "embeddings = []\n",
    "#strings_token is the tokenized sentences\n",
    "for s in strings_token:\n",
    "    #for each sentence create a vector to hold the embeddings for each token in the string\n",
    "    # it will be wiped each time\n",
    "    strings_embedding = []\n",
    "\n",
    "    #for each token in the sentence check if it has embedding and add it to the list or skip\n",
    "    for tkn in s:\n",
    "        if tkn in word2vec_googlenews:\n",
    "            strings_embedding.append(word2vec_googlenews[tkn])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    #use zip to put all elements from each embedding into list of the same index\n",
    "    embd = zip(*strings_embedding)\n",
    "    #calculate the average by finding the sum of the elements at each index, and dividing it by the number of elements\n",
    "    average_embedding = []\n",
    "    for e in embd:\n",
    "        avg = sum(e)/len(e)\n",
    "        average_embedding.append(avg)\n",
    "    #once all the averages are computed, append the average embedding as an element\n",
    "    embeddings.append(average_embedding)\n",
    "print(embeddings[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.4 Compute and display the overall hit rates of the training and test sets (i.e. the % of words in the Reddit posts for which an embedding is found in Word2Vec)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03008478338068182, 0.09322903373024681, 0.030028256503018467, 0.07418684525923296, -0.11172897165471857, -0.04322398792613636, 0.03311573375355114, -0.0864347978071733, 0.03924486853859641, 0.06014737215909091, -0.012917258522727272, -0.15264060280539773, 0.002850619229403409, 0.010581276633522728, -0.13426659323952414, 0.09747314453125, 0.04696932705965909, 0.14509721235795456, -0.020958640358664772, -0.10691972212357954, 0.009561018510298296, 0.07356678355823863, 0.13306149569424716, -0.02817327325994318, 0.10091330788352272, -0.05473605069247159, -0.048980712890625, 0.05866172096946023, 0.012480302290482954, -0.005160245028409091, -0.02615148370916193, 0.03894979303533381, -0.022986672141335228, -0.020204023881392044, 0.08096036044034091, -0.052642822265625, 0.008706526322798296, -0.0028459375554865055, 0.05139090798117898, 0.07250282981178978, 0.14099675958806818, -0.051161332563920456, 0.12253639914772728, -0.016482960094105114, -0.0491301796653054, -0.04001548073508523, -0.06283985484730113, -0.006010575727982955, 0.027651700106534092, 0.035019267689098015, 0.022304361516779118, 0.01167574795809659, -0.03792918812144886, -0.08046098188920454, 0.001190185546875, 0.02551824396306818, 0.013101057572798296, -0.06125710227272727, 0.053679032759232956, -0.06611563942649147, -0.07225322723388672, 0.09904584017666904, -0.10134332830255682, -0.10824376886541193, -0.04634371670809659, 0.014359907670454546, 0.014032537286931818, 0.06929987127130682, -0.042703801935369316, 0.04270518909801136, 0.0731201171875, 0.00018310546875, 0.05469582297585227, -0.009952891956676136, -0.1368408203125, -0.07500665838068182, 0.006342107599431818, 0.06371654163707387, 0.01566557450727983, 0.15640397505326706, 0.0016867897727272727, 0.005131808194247159, 0.019228805195201527, 0.03931912508877841, -0.11962335759943182, -0.08336292613636363, -0.06932137229225853, 0.16641443425958807, 0.036092584783380684, -0.004757967862215909, 0.07193756103515625, 0.030666004527698864, -0.05372203480113636, -0.07972023703835228, -0.015010486949573864, -0.07073419744318182, 0.047026200727982956, 0.037409002130681816, -0.05294192921031605, 0.019284335049715908, 0.00017478249289772728, -0.025355252352627842, 0.049333052201704544, 0.11363636363636363, 0.009538130326704546, -0.05434903231534091, -0.024662364612926136, -0.04205599698153409, 0.06489146839488637, -0.08537847345525568, -0.0093536376953125, -0.024187954989346592, -0.01639764959161932, 0.05160799893465909, 0.10670055042613637, -0.03909024325284091, 0.010999159379438921, 0.03200461647727273, 0.08821660822088068, 0.07369717684659091, -0.13490711558948865, 0.03165782581676136, -0.012141834605823864, 0.0827789306640625, -0.024878068403764206, -0.07743419300426137, -0.06294944069602272, -0.026304765181107956, 0.01211270419034091, -0.055150812322443184, -0.06829556551846591, -0.10083077170632103, -0.02327173406427557, -0.021279421719637783, -0.022189053622159092, -0.05259288441051136, 0.007457386363636364, -0.002347079190340909, -0.018267544833096592, -0.010123512961647728, 0.06872003728693182, -0.043298201127485794, -0.0006880326704545455, 0.010063864968039772, 0.016493797302246094, -0.002858248623934659, -0.013248790394176136, -0.06747159090909091, -0.04900290749289773, 0.040029352361505684, 0.05658652565696023, 0.040695017034357246, -0.08599786324934526, 0.04238475452769886, -0.013807816938920454, 0.007974451238458807, -0.06185635653409091, -0.06837047230113637, -0.07611222700639204, 0.014273903586647728, 0.03908100995150479, 0.05811968716708096, 0.03281749378551136, -0.014928644353693182, 0.02143651788884943, -0.07761452414772728, 0.03933438387784091, -0.07328657670454546, 0.03710174560546875, -0.06414517489346591, -0.12187125466086647, 0.045629327947443184, -0.017569802024147728, 0.0018310546875, -0.025608409534801136, -0.011278325861150568, 0.03700949928977273, -0.12109097567471591, -0.04097470370205966, -0.01563262939453125, -0.09259111231023615, -0.07395796342329546, 0.045587019486860794, 0.03329571810635654, 0.013782848011363636, -0.03789242831143466, -0.03448971835049716, -0.0008295232599431819, 0.04327115145596591, 0.033113653009588066, 0.01775568181818182, -0.00234222412109375, 0.018553300337357956, -0.028087269176136364, -0.07948719371448863, -0.014995228160511364, -0.030559193004261364, -0.06506625088778409, -0.03345558860085227, -0.10789004239169034, 0.0002940784801136364, -0.029558008367365055, -0.0008059414950284091, 0.0018213445490056818, 0.01319243691184304, -0.03985248912464489, -0.019428599964488636, -0.0028846047141335225, -0.0022735595703125, 0.010384299538352272, 0.012573588978160511, 0.054490522904829544, -0.026442787863991478, 0.06149222634055398, -0.09236699884588068, 0.032560868696732956, 0.09641057794744318, 0.036607222123579544, -0.06482211026278409, 0.018467296253551136, -0.03733132102272727, 0.03258999911221591, -0.05140269886363636, 0.005622170188210227, 0.11895751953125, -0.04700955477627841, 0.026444868607954544, 0.0005611072887073864, 0.08063853870738637, 0.050225691361860794, -0.030895579944957386, -0.001800537109375, 0.06081875887784091, 0.017417214133522728, 0.054719404740767044, -0.02825372869318182, -0.020673405040394176, -0.064422607421875, 0.05973122336647727, 0.005968960848721591, 0.008952400901100853, -0.032587224786931816, 0.05748748779296875, -0.12331043590198863, -0.007927114313299006, 0.034723455255681816, 0.007650808854536576, 0.06677350130948154, -0.022110592235218395, -0.017539284446022728, -0.034454345703125, 0.058091597123579544, 0.06421383944424716, 0.043183760209517044, 0.10434792258522728, -0.035231156782670456, 0.05000374533913352, 0.039968317205255684, -0.04268230091441761, -0.07714288884943182, -0.05766365744850852, 0.011829723011363636, -0.09678511186079546, 0.014565901322798296, 0.03133825822310014, 0.08293429287997159, -0.041487260298295456, -0.09430070356889204, -0.07825521989302202, -0.009614424272017046, 0.025360107421875, 0.14833762428977273, 0.14303484829989346, 0.02312677556818182, 0.0028242631392045455, -0.06425337357954546, -0.06514393199573863, -0.10504982688210228, -0.018536047501997513, -0.06214488636363636, 0.033986871892755684, -0.004766290838068182, 0.08314098011363637, 0.09604991566051137, 0.014776750044389204, -0.04011813077059659, -0.09477095170454546, -0.022696755149147728, 0.034169977361505684, 0.03632632168856534, -0.02404264970259233, 0.020923961292613636, -0.08191888982599432, 0.03771695223721591, -0.07708462801846591, -0.011363636363636364, 0.047090010209517044, 0.015104814009232954, 0.027604536576704544, -0.01632135564630682]\n",
      "positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34457571877546267\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "\n",
    "posts = []\n",
    "sentiment = []\n",
    "emotions = []\n",
    "for item in data:\n",
    "    posts.append(item[0])\n",
    "    sentiment.append(item[2])\n",
    "    emotions.append(item[1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, sentiment, test_size=0.2)\n",
    "\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "#x_numpy = numpy.array(X_train).reshape(-1,1)\n",
    "#y_numpy = numpy.array(y_train).reshape(-1,1)\n",
    "basemlp = MLPClassifier(max_iter=4)\n",
    "basemlp.fit(X_train, y_train)\n",
    "print(basemlp.score(X_test,y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.5 Train a Base-MLP: a Multi-Layered Perceptron (neural network.MLPClassifier) with the default parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.6 Train a Top-MLP: a better performing Multi-Layered Perceptron found with whatever hyperparameters you want."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosiers/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [10], line 10\u001B[0m\n\u001B[1;32m      4\u001B[0m param_grid \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mactivation\u001B[39m\u001B[38;5;124m'\u001B[39m : [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msigmoid\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtanh\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124midentity\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhidden_layer_sizes\u001B[39m\u001B[38;5;124m'\u001B[39m: [(\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m10\u001B[39m), (\u001B[38;5;241m30\u001B[39m,\u001B[38;5;241m50\u001B[39m)],\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msolver\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msgd\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      8\u001B[0m }\n\u001B[1;32m      9\u001B[0m mlp_grid \u001B[38;5;241m=\u001B[39m GridSearchCV(topmlp,param_grid,n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m \u001B[43mmlp_grid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTOP-MLP: \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(mlp_grid\u001B[38;5;241m.\u001B[39mscore(X_test, y_test))\n",
      "File \u001B[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    869\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    870\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    871\u001B[0m     )\n\u001B[1;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    879\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1379\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1377\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1378\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1379\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/sklearn/model_selection/_search.py:822\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    817\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    818\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    819\u001B[0m         )\n\u001B[1;32m    820\u001B[0m     )\n\u001B[0;32m--> 822\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    837\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    843\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    844\u001B[0m     )\n",
      "File \u001B[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/joblib/parallel.py:1098\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1098\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/joblib/parallel.py:975\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 975\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    977\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages/joblib/_parallel_backends.py:567\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    564\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    565\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.8/concurrent/futures/_base.py:439\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    436\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    437\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 439\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.8/threading.py:302\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 302\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    303\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "topmlp = MLPClassifier(max_iter=1)\n",
    "\n",
    "param_grid = {\n",
    "    'activation' : ['sigmoid', 'tanh', 'relu', 'identity'],\n",
    "    'hidden_layer_sizes': [(10,10,10), (30,50)],\n",
    "    'solver': ['sgd', 'adam']\n",
    "}\n",
    "mlp_grid = GridSearchCV(topmlp,param_grid,n_jobs=-1)\n",
    "mlp_grid.fit(X_train, y_train)\n",
    "print(\"TOP-MLP: \")\n",
    "print(mlp_grid.score(X_test, y_test))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.7  Display the performance of your classifiers using metrics.classification report and add these to your performance file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
